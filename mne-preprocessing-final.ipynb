{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7c1988-20ee-424e-ae46-92e6f1f3a4f3",
   "metadata": {},
   "source": [
    "# EEG preprocessing with MNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ac09e-fd4b-434e-a2bc-fe0e4c32dc62",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dadcdc-5983-41ee-8f2f-13e4ab05a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   participant_id       type\n",
      "0        sub-1448    Control\n",
      "1        sub-1824  Psychosis\n",
      "2        sub-1971    Control\n",
      "3        sub-1983  Psychosis\n",
      "4        sub-1989    Control\n",
      "..            ...        ...\n",
      "77      sub-2184A  Psychosis\n",
      "78      sub-2193A    Control\n",
      "79      sub-2214A    Control\n",
      "80      sub-2217A  Psychosis\n",
      "81      sub-2221A    Control\n",
      "\n",
      "[82 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#create dataframe from participants.tsv containing columns 1 and 2\n",
    "df_participants = pd.read_csv('../ds003944/participants.tsv', sep='\\t', usecols=[0,1])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with new channel names\n",
    "channels_new_names_dict = {\n",
    "    'EEG019':'FC5',\n",
    "    'EEG020':'FC1',\n",
    "    'EEG021':'FC2',\n",
    "    'EEG022':'FC6',\n",
    "    'EEG027':'C5',\n",
    "    'EEG028':'C3',\n",
    "    'EEG029':'C1',\n",
    "    'EEG030':'Cz',\n",
    "    'EEG031':'C2',\n",
    "    'EEG032':'C4',\n",
    "    'EEG033':'C6',\n",
    "    'EEG038':'CP3',\n",
    "    'EEG039':'CP1',\n",
    "    'EEG040': 'CP2',\n",
    "    'EEG041': 'CP4',\n",
    "    'EEG001': 'Fp1',\n",
    "    'EEG002': 'Fpz',\n",
    "    'EEG003': 'Fp2',\n",
    "    'EEG004': 'AF7',\n",
    "    'EEG005': 'AF3',\n",
    "    'EEG006': 'AF4',\n",
    "    'EEG008': 'F7',\n",
    "    'EEG009': 'F5',\n",
    "    'EEG010': 'F3',\n",
    "    'EEG011': 'F1',\n",
    "    'EEG012': 'Fz',\n",
    "    'EEG013': 'F2',\n",
    "    'EEG014': 'F4',\n",
    "    'EEG015': 'F6',\n",
    "    'EEG016': 'F8',\n",
    "    'EEG018': 'FT7',\n",
    "    'EEG023': 'FT8',\n",
    "    'EEG034': 'T8',\n",
    "    'EEG035': 'T10',\n",
    "    'EEG045': 'P5',\n",
    "    'EEG046': 'P3',\n",
    "    'EEG047': 'P1',\n",
    "    'EEG048': 'Pz',\n",
    "    'EEG049': 'P2',\n",
    "    'EEG050': 'P4',\n",
    "    'EEG051': 'P6',\n",
    "    'EEG052': 'P8',\n",
    "    'EEG053': 'PO7',\n",
    "    'EEG054': 'PO3',\n",
    "    'EEG055': 'PO4',\n",
    "    'EEG056': 'PO8',\n",
    "    'EEG057': 'O1',\n",
    "    'EEG058': 'Oz',\n",
    "    'EEG059': 'O2',\n",
    "    'EEG060': 'Iz',\n",
    "    \"EEG007\": 'AF6',\n",
    "    \"EEG017\": 'FT9',\n",
    "    \"EEG024\": 'FT10',\n",
    "    \"EEG025\": 'T9',\n",
    "    \"EEG026\": 'T7',\n",
    "    \"EEG042\": 'TP8',\n",
    "    \"EEG043\": 'TP10',\n",
    "    \"EEG044\": 'P7',\n",
    "    \"EEG061\": 'VEOG',\n",
    "    \"EEG062\": 'Misc',\n",
    "    \"EEG063\": 'ECG',\n",
    "    \"EEG064\": 'M2',\n",
    "    \"EEG036\": 'TP9',\n",
    "    \"EEG037\": 'TP7'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b249c15-a0df-4400-a7cb-a75ad5035b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ../ds003944-test/sub-1448/eeg/sub-1448_task-Rest_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 305999  =      0.000 ...   305.999 secs...\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.05 - 30 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.05, 30.00 Hz: -6.02, -6.02 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "{}\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 10 events and 30000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Fitting ICA to data using 61 channels (please be patient, this may take a while)\n",
      "Selecting by number: 50 components\n",
      " \n",
      "Fitting ICA took 187.3s.\n",
      "Using EOG channel: VEOG\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (50 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 61 PCA components\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 97.1 mm\n",
      "Computing interpolation matrix from 57 sensor positions\n",
      "Interpolating 4 sensors\n",
      "    Rejecting  epoch based on EEG : ['C4', 'CP2', 'CP4', 'Pz', 'P2']\n",
      "    Rejecting  epoch based on EEG : ['AF6']\n",
      "    Rejecting  epoch based on EEG : ['P2']\n",
      "    Rejecting  epoch based on EEG : ['FT8', 'T7']\n",
      "    Rejecting  epoch based on EEG : ['AF6']\n",
      "    Rejecting  epoch based on EEG : ['FC5']\n",
      "    Rejecting  epoch based on EEG : ['C1', 'P2', 'PO3', 'PO4', 'O1', 'O2', 'Iz']\n",
      "    Rejecting  epoch based on EEG : ['PO8']\n",
      "    Rejecting  epoch based on EEG : ['Cz', 'CP1', 'CP2', 'CP4', 'P1', 'Pz', 'P2', 'O2']\n",
      "9 bad epochs dropped\n",
      "Extracting parameters from ../ds003944-test/sub-1824/eeg/sub-1824_task-Rest_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 300999  =      0.000 ...   300.999 secs...\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.05 - 30 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.05, 30.00 Hz: -6.02, -6.02 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "{}\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 10 events and 30000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Fitting ICA to data using 61 channels (please be patient, this may take a while)\n",
      "Selecting by number: 50 components\n",
      " \n",
      "Fitting ICA took 189.5s.\n",
      "Using EOG channel: VEOG\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (50 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 61 PCA components\n",
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 97.1 mm\n",
      "Computing interpolation matrix from 57 sensor positions\n",
      "Interpolating 4 sensors\n",
      "    Rejecting  epoch based on EEG : ['AF7', 'P5', 'P3', 'P1', 'PO7', 'PO3', 'PO4', 'PO8']\n",
      "1 bad epochs dropped\n",
      "Extracting parameters from ../ds003944-test/sub-1971/eeg/sub-1971_task-Rest_eeg.vhdr...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\dev\\\\python\\\\ds003944-test\\\\sub-1971\\\\eeg\\\\sub-1971_task-Rest_eeg.vhdr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#run the below code for each subject using vmrk files within folder that name equals value in column 1 of df_participants\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df_participants\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m      4\u001b[0m     \u001b[39m#reading brainvision files\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     brainvision_raw \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_raw_brainvision(\n\u001b[0;32m      6\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../ds003944-test/\u001b[39;49m\u001b[39m{\u001b[39;49;00mrow[\u001b[39m\"\u001b[39;49m\u001b[39mparticipant_id\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m/eeg/\u001b[39;49m\u001b[39m{\u001b[39;49;00mrow[\u001b[39m\"\u001b[39;49m\u001b[39mparticipant_id\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m_task-Rest_eeg.vhdr\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m         preload\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      9\u001b[0m     brainvision_fname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../ds003944-test/\u001b[39m\u001b[39m{\u001b[39;00mrow[\u001b[39m\"\u001b[39m\u001b[39mparticipant_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/eeg/\u001b[39m\u001b[39m{\u001b[39;00mrow[\u001b[39m\"\u001b[39m\u001b[39mparticipant_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_task-Rest_eeg.vhdr\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[39m#renaming channels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\python\\.venv\\Lib\\site-packages\\mne\\io\\brainvision\\brainvision.py:888\u001b[0m, in \u001b[0;36mread_raw_brainvision\u001b[1;34m(vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39m@fill_doc\u001b[39m\n\u001b[0;32m    855\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_raw_brainvision\u001b[39m(vhdr_fname,\n\u001b[0;32m    856\u001b[0m                          eog\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mHEOGL\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mHEOGR\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVEOGb\u001b[39m\u001b[39m'\u001b[39m), misc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    857\u001b[0m                          scale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, preload\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    858\u001b[0m     \u001b[39m\"\"\"Reader for Brain Vision EEG file.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \n\u001b[0;32m    860\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m    mne.io.Raw : Documentation of attribute and methods.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 888\u001b[0m     \u001b[39mreturn\u001b[39;00m RawBrainVision(vhdr_fname\u001b[39m=\u001b[39;49mvhdr_fname, eog\u001b[39m=\u001b[39;49meog,\n\u001b[0;32m    889\u001b[0m                           misc\u001b[39m=\u001b[39;49mmisc, scale\u001b[39m=\u001b[39;49mscale, preload\u001b[39m=\u001b[39;49mpreload,\n\u001b[0;32m    890\u001b[0m                           verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[1;32m<decorator-gen-242>:12\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\dev\\python\\.venv\\Lib\\site-packages\\mne\\io\\brainvision\\brainvision.py:75\u001b[0m, in \u001b[0;36mRawBrainVision.__init__\u001b[1;34m(self, vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n\u001b[0;32m     72\u001b[0m ext \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39msplitext(hdr_fname)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m ahdr_format \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m ext \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.ahdr\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     74\u001b[0m (info, data_fname, fmt, order, n_samples, mrk_fname, montage,\n\u001b[1;32m---> 75\u001b[0m  orig_units) \u001b[39m=\u001b[39m _get_hdr_info(hdr_fname, eog, misc, scale)\n\u001b[0;32m     77\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(data_fname, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fmt, \u001b[39mdict\u001b[39m):  \u001b[39m# ASCII, this will be slow :(\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\python\\.venv\\Lib\\site-packages\\mne\\io\\brainvision\\brainvision.py:475\u001b[0m, in \u001b[0;36m_get_hdr_info\u001b[1;34m(hdr_fname, eog, misc, scale)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[39mif\u001b[39;00m ext \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m.vhdr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.ahdr\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    472\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe header file must be given to read the data, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mnot a file with extension \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m ext)\n\u001b[1;32m--> 475\u001b[0m settings, cfg, cinfostr, info \u001b[39m=\u001b[39m _aux_hdr_info(hdr_fname)\n\u001b[0;32m    476\u001b[0m info\u001b[39m.\u001b[39m_unlocked \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    478\u001b[0m order \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mget(cinfostr, \u001b[39m'\u001b[39m\u001b[39mDataOrientation\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\dev\\python\\.venv\\Lib\\site-packages\\mne\\io\\brainvision\\brainvision.py:376\u001b[0m, in \u001b[0;36m_aux_hdr_info\u001b[1;34m(hdr_fname)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_aux_hdr_info\u001b[39m(hdr_fname):\n\u001b[0;32m    375\u001b[0m     \u001b[39m\"\"\"Aux function for _get_hdr_info.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(hdr_fname, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    377\u001b[0m         \u001b[39m# extract the first section to resemble a cfg\u001b[39;00m\n\u001b[0;32m    378\u001b[0m         header \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadline()\n\u001b[0;32m    379\u001b[0m         codepage \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\dev\\\\python\\\\ds003944-test\\\\sub-1971\\\\eeg\\\\sub-1971_task-Rest_eeg.vhdr'"
     ]
    }
   ],
   "source": [
    "#run the below code for each subject using vmrk files within folder that name equals value in column 1 of df_participants\n",
    "\n",
    "for index, row in df_participants.iterrows():\n",
    "    #reading brainvision files\n",
    "    brainvision_raw = mne.io.read_raw_brainvision(\n",
    "        f'../ds003944-test/{row[\"participant_id\"]}/eeg/{row[\"participant_id\"]}_task-Rest_eeg.vhdr',\n",
    "        preload=True)\n",
    "\n",
    "    brainvision_fname = f'../ds003944-test/{row[\"participant_id\"]}/eeg/{row[\"participant_id\"]}_task-Rest_eeg.vhdr'\n",
    "\n",
    "    \n",
    "    #renaming channels\n",
    "    brainvision_raw.rename_channels(channels_new_names_dict)\n",
    "\n",
    "    #setting channel types\n",
    "    brainvision_raw.set_channel_types({\n",
    "        'VEOG':'eog',\n",
    "        'ECG':'ecg',\n",
    "        'Misc':'misc',\n",
    "        'M2':'eeg'\n",
    "    })\n",
    "\n",
    "    #setting montage\n",
    "    brainvision_raw.set_montage('standard_1020')\n",
    "\n",
    "    #filtering data\n",
    "    mat_nyquist_freq = brainvision_raw.info[\"sfreq\"] / 2\n",
    "    brainvision_raw.notch_filter(freqs=np.arange(50, mat_nyquist_freq, 50), picks='eeg')\n",
    "    brainvision_raw.filter(0.05, 30, method=\"iir\", picks='eeg')\n",
    "\n",
    "    #setting reference\n",
    "    reference = 'average'\n",
    "    brainvision_raw.set_eeg_reference(ref_channels=reference)\n",
    "    reference = ['M2']\n",
    "    brainvision_raw.set_eeg_reference(ref_channels=reference)\n",
    "\n",
    "    #data segmentation into epochs\n",
    "    events_from_annotations, events_dict_from_annotations = mne.events_from_annotations(brainvision_raw)\n",
    "    print(events_dict_from_annotations)\n",
    "    mat_epochs = mne.make_fixed_length_epochs(brainvision_raw, duration=30, preload=True)\n",
    "\n",
    "    #occular correction with ICA\n",
    "    ica = mne.preprocessing.ICA(n_components=50, random_state=42, method=\"infomax\")\n",
    "    ica.fit(mat_epochs)\n",
    "    ica.exclude=[]\n",
    "    eog_indices, eog_sources = ica.find_bads_eog(\n",
    "        mat_epochs, \n",
    "        measure='zscore', \n",
    "        threshold='auto'\n",
    "    )\n",
    "    ica.exclude = eog_indices\n",
    "    ica.apply(mat_epochs)\n",
    "\n",
    "    #interpolating bad channels\n",
    "    mat_epochs.info['bads'] = ['Fp1', 'Fp2', 'AF3', 'AF4']\n",
    "    mat_epochs = mat_epochs.interpolate_bads(reset_bads=False)\n",
    "\n",
    "    #artifact rejection\n",
    "    reject_criteria = dict(eeg=150e-6)\n",
    "    mat_epochs.drop_bad(reject=reject_criteria)\n",
    "\n",
    "    #saving epochs to fif file\n",
    "    dir_to_store_fif = \"../eggML-project/preprocessed-data/\"\n",
    "    start = brainvision_fname.index(\"sub-\")\n",
    "    end = brainvision_fname.index(\"/eeg\")\n",
    "    sub_id = brainvision_fname[start:end]\n",
    "    mat_epochs.save(f\"{dir_to_store_fif}{sub_id}-epo.fif\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3e24353c4a449eb3c40ff9c25ce82bbcd406208b3e91f730cf22ee9dfc8dd5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
